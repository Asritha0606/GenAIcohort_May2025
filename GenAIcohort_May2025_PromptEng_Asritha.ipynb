{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPF5KkeHb/cChVXUOnvuIn5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asritha0606/GenAIcohort_May2025/blob/main/GenAIcohort_May2025_PromptEng_Asritha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eZdBH0X3Ayn",
        "outputId": "a01ea853-ae11-4f30-b97d-b0f6098e1e02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.6/129.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "groq_api_key = userdata.get('groq_api')\n",
        "os.environ[\"GROQ_API_KEY\"] = groq_api_key"
      ],
      "metadata": {
        "id": "jJ2mUdhV31_f"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "client = Groq(\n",
        "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
        ")\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain the importance of large language models\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama3-8b-8192\",\n",
        ")\n",
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcpGjLWz4GwO",
        "outputId": "75934a39-3953-4a0f-c9d1-bc6d694d98a1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Large language models (LLMs) have become a crucial component in the field of natural language processing (NLP) in recent years. These models have demonstrated impressive capabilities in understanding, generating, and processing human language, which has numerous implications across various industries and applications. Here are the importance of large language models:\n",
            "\n",
            "1. **Improved Language Understanding**: LLMs can analyze vast amounts of text data, understand complex relationships, and identify nuances in language that were previously difficult to grasp. This improved understanding enables better processing of unstructured data, facilitating applications like sentiment analysis, question-answering, and text classification.\n",
            "2. **Enhanced Language Generation**: LLMs can generate human-like text, which is critical for applications like chatbots, language translation, and content creation. The ability to generate coherent and meaningful text has far-reaching implications for industries like marketing, customer service, and education.\n",
            "3. **Efficient Knowledge Retrieval**: LLMs can quickly locate and retrieve relevant information from vast amounts of text data, making them an invaluable tool for researchers, students, and professionals seeking to stay up-to-date with the latest developments in their domain.\n",
            "4. **Insightful Sentiment Analysis**: LLMs can accurately analyze sentiments, emotions, and opinions expressed in text, helping companies gauge consumer sentiment, identify trends, and make data-driven decisions.\n",
            "5. **Breaking Language Barriers**: LLMs can facilitate language translation and enable communication across languages, cultures, and geographical boundaries. This has significant implications for international business, education, and diplomacy.\n",
            "6. **Improved Customer Service**: LLMs can be integrated with customer service platforms to provide personalized responses, reducing response times, and improving customer satisfaction.\n",
            "7. **Healthcare and Medical Research**: LLMs can help process vast amounts of medical data, enabling researchers to identify patterns, and develop new treatments and cures for diseases.\n",
            "8. **Enhanced Education**: LLMs can assist personalized learning, providing students with adaptive learning resources, and enabling teachers to focus on more complex tasks.\n",
            "9. **Cybersecurity**: LLMs can detect and prevent cyber threats by analyzing malicious code, identifying patterns, and flagging suspicious activity.\n",
            "10. **Foundational Research**: LLMs have opened up new research areas, such as graph-based models, attention mechanisms, and transformers, which are essential for advancing the field of NLP.\n",
            "11. **Scaling Industry-Specific Solutions**: LLMs can be fine-tuned for specific industries, enabling solutions for industries like law, finance, and hospitality, where language plays a critical role in decision-making.\n",
            "12. **Exploration of New Frontiers**: LLMs have paved the way for natural language processing in tasks like dialogue systems, named entity recognition, and question-answering, which have far-reaching implications for various industries and applications.\n",
            "\n",
            "In summary, large language models have revolutionized the field of NLP, enabling massive improvements in language understanding, generation, and processing. Their impact is felt across various industries, from customer service and education to healthcare, cybersecurity, and foundation research.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 1: Summary Extraction"
      ],
      "metadata": {
        "id": "NMgL6g8s5COY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove special symbols and multiple punctuation\n",
        "    text = re.sub(r'[^\\w\\s\\.\\,\\-\\']', ' ', text)  # keep alphanumerics and punctuation\n",
        "    text = re.sub(r'\\s+', ' ', text)  # replace multiple spaces with one\n",
        "    text = re.sub(r'\\.\\.+', '.', text)  # replace ellipses with a single period\n",
        "    text = re.sub(r'(?<=\\w)[A-Z]', lambda x: ' ' + x.group(0), text)  # fix camel-case issues\n",
        "    text = re.sub(r'\\s([?.!,\"](?:\\s|$))', r'\\1', text)  # remove space before punctuation\n",
        "    return text.strip()\n"
      ],
      "metadata": {
        "id": "r27Hg7U95EeW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_text(text):\n",
        "    cleaned = clean_text(text)\n",
        "    prompt = f\"Summarise my text: {cleaned}\"\n",
        "    return prompt\n"
      ],
      "metadata": {
        "id": "XXXt2lv95IC3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text = \"\"\"\n",
        "Black..... holes—those mysterious cosmic phenomena—are regions in space with gravitational forces so intense that not even light can escape. Astrophysicists Dr. Alan Rothwell and Prof. Priya Sinha### have dived deeply into the “science” of these objects, uncovering fascinating insights! According to Rothwell’s research (2021), black holes form when massive stars burn ^^^^through their fuel & collapse under gravity until they reach a singularity—a point of (nearly) infinite density, where physics bReak dOwn.\n",
        "\n",
        "Sinha’s studies focus on the event horizon, or the “point of no return”; any matter or light crossing this boundary is trapped forever. Sinha also examines Hawking Radiation—a theoretical ....concept from Stephen Hawking—suggesting that black holes.... emit small amounts of energy...., slowly losing mass. Such radiation might allow scientists to peek inside these intense entities!!!!. Together, Rothwell and Sinha’s studies hint at bridging quantum mechanics w/ general relativity—fields otherwise tough to reconcile!\n",
        "\"\"\"\n",
        "\n",
        "cleaned = clean_text(raw_text)\n",
        "prompt = summarize_text(raw_text)\n",
        "\n",
        "print(\"Cleaned Text:\\n\", cleaned)\n",
        "print(\"\\nPrompt:\\n\", prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sesDpU8X5JMa",
        "outputId": "1a922893-7500-454e-cb5f-42162ee6bf57"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Text:\n",
            " Black. holes those mysterious cosmic phenomena are regions in space with gravitational forces so intense that not even light can escape. Astrophysicists Dr. Alan Rothwell and Prof. Priya Sinha have dived deeply into the science of these objects, uncovering fascinating insights According to Rothwell s research 2021, black holes form when massive stars burn through their fuel collapse under gravity until they reach a singularity a point of nearly infinite density, where physics b Reak d Own. Sinha s studies focus on the event horizon, or the point of no return any matter or light crossing this boundary is trapped forever. Sinha also examines Hawking Radiation a theoretical .concept from Stephen Hawking suggesting that black holes. emit small amounts of energy., slowly losing mass. Such radiation might allow scientists to peek inside these intense entities. Together, Rothwell and Sinha s studies hint at bridging quantum mechanics w general relativity fields otherwise tough to reconcile\n",
            "\n",
            "Prompt:\n",
            " Summarise my text: Black. holes those mysterious cosmic phenomena are regions in space with gravitational forces so intense that not even light can escape. Astrophysicists Dr. Alan Rothwell and Prof. Priya Sinha have dived deeply into the science of these objects, uncovering fascinating insights According to Rothwell s research 2021, black holes form when massive stars burn through their fuel collapse under gravity until they reach a singularity a point of nearly infinite density, where physics b Reak d Own. Sinha s studies focus on the event horizon, or the point of no return any matter or light crossing this boundary is trapped forever. Sinha also examines Hawking Radiation a theoretical .concept from Stephen Hawking suggesting that black holes. emit small amounts of energy., slowly losing mass. Such radiation might allow scientists to peek inside these intense entities. Together, Rothwell and Sinha s studies hint at bridging quantum mechanics w general relativity fields otherwise tough to reconcile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q litellm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cQh7gje6D2f",
        "outputId": "232ca27c-045e-4dea-e51f-63ecb17650ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/8.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/8.0 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m120.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from litellm import completion"
      ],
      "metadata": {
        "id": "WwIVqTt_6Ao1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(prompt):\n",
        "  #define model\n",
        "  model=\"groq/llama3-70b-8192\"\n",
        "  messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "  #call responses\n",
        "  response = completion(\n",
        "      model=model,\n",
        "      messages=messages\n",
        "  )\n",
        "\n",
        "  return response['choices'][0]['message']['content'] or \"\"\n"
      ],
      "metadata": {
        "id": "PlQNQofx514D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = get_response(prompt)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQQe5PKi53Yh",
        "outputId": "6cdba456-adcc-48a6-fd26-735779be9226"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is a summary of your text:\n",
            "\n",
            "Astrophysicists Dr. Alan Rothwell and Prof. Priya Sinha have made significant discoveries about black holes, regions in space with gravity so strong that not even light can escape. Rothwell's research shows that black holes are created when massive stars collapse under gravity until they form a singularity of infinite density. Sinha's studies focus on the event horizon, where anything that crosses it is trapped forever, and Hawking Radiation, which suggests that black holes emit small amounts of energy and may allow scientists to peek inside them. Their research may help bridge the gap between quantum mechanics and general relativity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 2: Sentiment Analysis"
      ],
      "metadata": {
        "id": "-0cAksU5aah8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment(review):\n",
        "    prompt = f\"\"\"\n",
        "Your task is to classify the sentiment of a user's review as Positive, Negative, or Neutral.\n",
        "\n",
        "<review>: I absolutely loved the new update—it’s so user-friendly and fast!\n",
        "<sentiment>: Positive\n",
        "\n",
        "<review>: {review}\n",
        "<sentiment>:\"\"\"\n",
        "\n",
        "    return get_response(prompt).strip()\n"
      ],
      "metadata": {
        "id": "tljEOFZD6W9C"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = \"The app crashes every time I try to upload a file.\"\n",
        "sentiment = get_sentiment(review)\n",
        "print(\"Sentiment:\", sentiment)\n"
      ],
      "metadata": {
        "id": "piDpHDZr7ygD",
        "outputId": "bb375d0b-840f-4b83-f505-788413b731ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: <sentiment>: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 3: Intelligent Resume Filtering using Keyword Extraction\n"
      ],
      "metadata": {
        "id": "d9WBS_YdaTVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLP Approach"
      ],
      "metadata": {
        "id": "b_HgmFzVaQF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def parse_hiring_query(query):\n",
        "    filters = {\n",
        "        \"work_experience\": None,\n",
        "        \"technical_skills\": [],\n",
        "        \"designation\": None,\n",
        "        \"education\": None,\n",
        "        \"location\": None\n",
        "    }\n",
        "\n",
        "    # Lowercase for normalization\n",
        "    q = query.lower()\n",
        "\n",
        "    # 1. Extract years of experience\n",
        "    match = re.search(r'(\\d+)\\s+years?', q)\n",
        "    if match:\n",
        "        filters[\"work_experience\"] = int(match.group(1))\n",
        "\n",
        "    # 2. Extract skills - define a known skill list (can be from DB)\n",
        "    known_skills = ['python', 'java', 'flask', 'react', 'nodejs', 'sql', 'mongodb', 'c++', 'aws', 'docker']\n",
        "    for skill in known_skills:\n",
        "        if re.search(rf'\\b{skill}\\b', q):\n",
        "            filters[\"technical_skills\"].append(skill)\n",
        "\n",
        "    # 3. Extract location - look for \"in <location>\" or \"at <location>\" or \"work in <location>\"\n",
        "    loc_match = re.search(r'(?:in|at|work in)\\s+([a-zA-Z\\s]+)', q)\n",
        "    if loc_match:\n",
        "        location = loc_match.group(1).strip().title()\n",
        "        filters[\"location\"] = location\n",
        "\n",
        "    # Build MongoDB query\n",
        "    mongo_query = {}\n",
        "\n",
        "    if filters[\"work_experience\"] is not None:\n",
        "        mongo_query[\"work_experience\"] = {\"$eq\": filters[\"work_experience\"]}\n",
        "\n",
        "    if filters[\"technical_skills\"]:\n",
        "        mongo_query[\"technical_skills\"] = {\"$in\": filters[\"technical_skills\"]}\n",
        "\n",
        "    if filters[\"location\"]:\n",
        "        mongo_query[\"location\"] = {\"$regex\": filters[\"location\"], \"$options\": \"i\"}\n",
        "\n",
        "    return mongo_query\n"
      ],
      "metadata": {
        "id": "IRj33AgrW2z2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Get me candidates with 2 years experience in python and flask and ready to work in Banglore\"\n",
        "print(parse_hiring_query(query))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsMDX90yW--i",
        "outputId": "f3184aa6-74eb-4173-f1c8-d8abae35a585"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'work_experience': {'$eq': 2}, 'technical_skills': {'$in': ['python', 'flask']}, 'location': {'$regex': 'Python And Flask And Ready To Work In Banglore', '$options': 'i'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM-based prompt"
      ],
      "metadata": {
        "id": "ROBC_p1XaNGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "import ast\n",
        "\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
        "client = Groq(api_key=GROQ_API_KEY)\n",
        "\n",
        "FILTERS = [\"work_experience\", \"technical_skills\", \"designation\", \"education\", \"location\"]\n",
        "\n",
        "def generate_llm_prompt(query: str):\n",
        "    return f\"\"\"\n",
        "You are an expert MongoDB engineer.\n",
        "Your job is to extract keywords from a hiring manager's query and return a VALID PyMongo query.\n",
        "\n",
        "Filters to consider:\n",
        "{FILTERS}\n",
        "\n",
        "Instructions:\n",
        "1. Map experience (e.g., \"3 years\") to `work_experience.years`.\n",
        "2. Map skills (e.g., \"Python\", \"Flask\") to `technical_skills.skill`.\n",
        "3. Map places (e.g., \"Bangalore\", \"Delhi\") to `location`.\n",
        "4. Use `$gte` for experience comparisons.\n",
        "5. Use `$in` for lists.\n",
        "6. Only return the MongoDB query (as a Python dictionary). No explanation.\n",
        "\n",
        "Hiring Manager Query:\n",
        "\\\"{query}\\\"\n",
        "\"\"\"\n",
        "\n",
        "def get_mongodb_query_from_llm(prompt: str):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama3-70b-8192\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.2\n",
        "    )\n",
        "\n",
        "    # Extract and safely evaluate the dictionary\n",
        "    raw_query = response.choices[0].message.content.strip()\n",
        "\n",
        "    try:\n",
        "        parsed_query = ast.literal_eval(raw_query)\n",
        "        return parsed_query\n",
        "    except Exception as e:\n",
        "        print(\"Error parsing query:\", e)\n",
        "        print(\"Raw output:\", raw_query)\n",
        "        return {}\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    hiring_query = \"I want candidates with 3 years experience in Java or Node.js, based in Delhi\"\n",
        "    prompt = generate_llm_prompt(hiring_query)\n",
        "    mongo_query = get_mongodb_query_from_llm(prompt)\n",
        "\n",
        "\n",
        "    print(mongo_query)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyOBnv2vZcN9",
        "outputId": "948a1944-5b72-4b9a-a115-40f8d6cdbd60"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'$and': [{'work_experience.years': {'$gte': 3}}, {'technical_skills.skill': {'$in': ['Java', 'Node.js']}}, {'location': 'Delhi'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment: Building a Smart Assistant for Virtual Healthcare Support"
      ],
      "metadata": {
        "id": "jKT-SvU2sh0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement: Given a doctor-patient conversation, the AI assistant should help by:\n",
        "\n",
        "Detecting the patient's emotional state. Give a score on a scale of 1-5.\n",
        "Summarizing the chief complaint and urgency of the patient.\n",
        "\n"
      ],
      "metadata": {
        "id": "pOZoZrCGsuzo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Tools:\n",
        "\n",
        "*   EmotionDetectionTool: analyzes patient’s emotional state and returns an emotion label + score (1-5).\n",
        "\n",
        "*   ChiefComplaintSummaryTool: summarizes the patient's main complaint and assesses urgency.\n",
        "\n"
      ],
      "metadata": {
        "id": "z-shz-8cw5Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q groq langchain-groq langchain langchain-community langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhtf38qnLknP",
        "outputId": "89f4467f-5c78-4233-f374-02754f7a83e1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain_core.tools import tool\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.messages import HumanMessage, ToolMessage, AIMessage\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from typing import List\n",
        "from litellm import completion\n",
        "from langchain.agents import initialize_agent, Tool, AgentType"
      ],
      "metadata": {
        "id": "-dXveAimLrPw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.3-70b-versatile\", #\"llama-3.1-8b-instant\",\n",
        "    temperature=0, # range of temperature variable is from 0(least artistic) to 1(most artistic/enhanced)\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")"
      ],
      "metadata": {
        "id": "OUoskUaZLtdx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "from langchain_core.language_models import BaseLanguageModel\n",
        "\n",
        "\n",
        "@tool\n",
        "def detect_patient_emotion(conversation: str) -> dict:\n",
        "    \"\"\"\n",
        "    Analyzes a doctor-patient conversation to extract:\n",
        "    1. Patient's emotion (e.g., anxious, calm, in pain)\n",
        "    2. Emotion score on a scale from 1 to 5 (1 = very distressed, 5 = calm)\n",
        "\n",
        "    Parameters:\n",
        "    - conversation (str): The full conversation text.\n",
        "\n",
        "    Returns:\n",
        "    - dict: Contains \"emotion\" and \"emotion_score\" as keys.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Analyze the following conversation between a doctor and a patient.\n",
        "\n",
        "    Extract only:\n",
        "    - Patient's primary emotional state (one word)\n",
        "    - Emotion score from 1 to 5 (1 = very distressed, 5 = calm)\n",
        "\n",
        "    Format your response exactly like this:\n",
        "    emotion: <emotion>\n",
        "    emotion_score: <score>\n",
        "\n",
        "    Conversation:\n",
        "    {conversation}\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "    raw_output = response.content.strip()\n",
        "\n",
        "    # Simple parsing without using Pydantic\n",
        "    result = {}\n",
        "    for line in raw_output.splitlines():\n",
        "        if \":\" in line:\n",
        "            key, value = line.split(\":\", 1)\n",
        "            result[key.strip()] = value.strip()\n",
        "\n",
        "    # Optional: Convert score to int\n",
        "    try:\n",
        "        result[\"emotion_score\"] = int(result[\"emotion_score\"])\n",
        "    except:\n",
        "        result[\"emotion_score\"] = None  # fallback if score parsing fails\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "4fbSkLDIsgDh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "@tool\n",
        "def summarize_chief_complaint(conversation: str) -> dict:\n",
        "    \"\"\"\n",
        "    Summarizes the chief complaint and urgency of the patient from a doctor-patient conversation.\n",
        "\n",
        "    Parameters:\n",
        "    - conversation (str): The full doctor-patient conversation.\n",
        "\n",
        "    Returns:\n",
        "    - dict: Contains 'chief_complaint' and 'urgency_level' (on a scale of 1–5).\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Analyze the following doctor-patient conversation.\n",
        "\n",
        "    Extract:\n",
        "    1. Chief complaint (main health issue described by the patient) – a brief sentence.\n",
        "    2. Urgency level (1 to 5), where:\n",
        "       - 1 = not urgent\n",
        "       - 5 = extremely urgent and needs immediate attention\n",
        "\n",
        "    Format your response exactly like this:\n",
        "    chief_complaint: <complaint>\n",
        "    urgency_level: <1-5>\n",
        "\n",
        "    Conversation:\n",
        "    {conversation}\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "    raw_output = response.content.strip()\n",
        "\n",
        "    # Parse response into dictionary\n",
        "    result = {}\n",
        "    for line in raw_output.splitlines():\n",
        "        if \":\" in line:\n",
        "            key, value = line.split(\":\", 1)\n",
        "            result[key.strip()] = value.strip()\n",
        "\n",
        "    try:\n",
        "        result[\"urgency_level\"] = int(result[\"urgency_level\"])\n",
        "    except:\n",
        "        result[\"urgency_level\"] = None\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "3rjZcwkNLZxL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "\n",
        "emotion_tool = Tool(\n",
        "    name=\"EmotionDetectionTool\",\n",
        "    func=detect_patient_emotion,\n",
        "    description=\"Detect the patient's emotional state and return an emotion label and score from 1 to 5.\"\n",
        ")\n",
        "\n",
        "complaint_tool = Tool(\n",
        "    name=\"ChiefComplaintSummaryTool\",\n",
        "    func=summarize_chief_complaint,\n",
        "    description=\"Summarize the patient's chief complaint and determine urgency (low, medium, high).\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "jmCgnf7dMMFP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
        "from langchain_core.prompts import ChatPromptTemplate # New import for the prompt template\n",
        "\n",
        "# Define your tools (assume emotion_tool and complaint_tool are already defined)\n",
        "tools = [emotion_tool, complaint_tool]\n",
        "\n",
        "# Define the prompt template for the tool calling agent\n",
        "# This replaces the need to import TOOL_CALLING_PROMPT directly\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "])\n",
        "\n",
        "\n",
        "# Create the agent\n",
        "# Remove the 'output_parser' and 'format_scratchpad' arguments\n",
        "agent = create_tool_calling_agent(\n",
        "    llm,\n",
        "    tools,\n",
        "    prompt\n",
        ")\n",
        "\n",
        "\n",
        "# Wrap the agent into an executor\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "t3v71ahhOE2V"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = \"\"\"\n",
        "Doctor: Hello, how are you feeling today?\n",
        "Patient: I've been having chest pains and shortness of breath. It's making me very anxious.\n",
        "Doctor: I see, let's take a closer look.\n",
        "\"\"\"\n",
        "\n",
        "response = agent_executor.invoke({\n",
        "    \"input\": f\"Analyze this conversation:\\n{conversation}\\n\\nPlease detect the patient's emotional state and summarize the chief complaint with urgency.\"\n",
        "})\n",
        "\n",
        "print(response[\"output\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMyQvAkGMaun",
        "outputId": "873cbc6d-48dc-4e45-a42a-ac4f493010cc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `EmotionDetectionTool` with `I've been having chest pains and shortness of breath. It's making me very anxious.`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m{'emotion': 'anxious', 'emotion_score': 2}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `ChiefComplaintSummaryTool` with `I've been having chest pains and shortness of breath. It's making me very anxious.`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m{'chief_complaint': 'The patient is experiencing chest pains and shortness of breath.', 'urgency_level': 5}\u001b[0m\u001b[32;1m\u001b[1;3mThe patient's emotional state is anxious with a score of 2, and the chief complaint is chest pains and shortness of breath with a high urgency level.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The patient's emotional state is anxious with a score of 2, and the chief complaint is chest pains and shortness of breath with a high urgency level.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = \"\"\"\n",
        "Doctor: Good morning! How are you feeling today?\n",
        "\n",
        "Patient: Good morning, Doctor. I’m feeling much better than last week, thank you.\n",
        "\n",
        "Doctor: That’s wonderful to hear. Were you able to take all the medications as prescribed?\n",
        "\n",
        "Patient: Yes, I followed the instructions exactly. I think they really helped.\n",
        "\n",
        "Doctor: Excellent. Any side effects or issues?\n",
        "\n",
        "Patient: Not really. Just a bit of drowsiness the first couple of days, but that’s gone now.\n",
        "\n",
        "Doctor: That’s perfectly normal. I'm glad you're doing well. How is your energy level?\n",
        "\n",
        "Patient: Much better. I’ve even started going on short walks again.\n",
        "\n",
        "Doctor: That’s fantastic progress! Keep that up, and we’ll gradually increase your activity. Do you have any concerns or questions?\n",
        "\n",
        "Patient: No concerns for now. Just grateful for the care.\n",
        "\n",
        "Doctor: You’re doing great. Let’s do a follow-up in two weeks to make sure things stay on track.\n",
        "\n",
        "Patient: Sounds good. Thanks again, Doctor!\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "response = agent_executor.invoke({\n",
        "    \"input\": f\"Analyze this conversation:\\n{conversation}\\n\\nPlease detect the patient's emotional state and summarize the chief complaint with urgency.\"\n",
        "})\n",
        "\n",
        "print(response[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5Uzd_okMyiX",
        "outputId": "05ddadb6-2a0b-4c10-de0d-2f910637f9d0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `EmotionDetectionTool` with `The patient is feeling grateful and positive about their progress, with no concerns or negative emotions expressed.`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m{'emotion': 'Grateful', 'emotion_score': 5}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `ChiefComplaintSummaryTool` with `The patient's chief complaint is not explicitly stated, but based on the context, it appears they were being treated for an illness or condition that has improved with medication and rest. The urgency is low since the patient is feeling better and has no concerns.`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m{'chief_complaint': \"The patient's condition has improved with medication and rest.\", 'urgency_level': 1}\u001b[0m\u001b[32;1m\u001b[1;3mThe patient's emotional state is detected as \"Grateful\" with a score of 5, indicating a very positive emotional state. The chief complaint summary indicates that the patient's condition has improved with medication and rest, and the urgency level is low (1), suggesting that the patient is stable and requires routine follow-up care.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The patient's emotional state is detected as \"Grateful\" with a score of 5, indicating a very positive emotional state. The chief complaint summary indicates that the patient's condition has improved with medication and rest, and the urgency level is low (1), suggesting that the patient is stable and requires routine follow-up care.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task: Customer Review Extraction"
      ],
      "metadata": {
        "id": "HEKaBcpzQ1Ti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Extract the customer(name & ID), product and company details\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Extract the sentiment of the customer\n",
        "\n",
        "\n",
        "\n",
        "*   What was good or bad about the product- give specific details\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EmkB8zKVTntr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel\n",
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "id": "h-eE0TqaQ4CS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewExtractionOutput(BaseModel):\n",
        "    customer_name: str\n",
        "    customer_id: str\n",
        "    product: str\n",
        "    company: str\n",
        "    sentiment: str\n",
        "    pros: str\n",
        "    cons: str\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=ReviewExtractionOutput)\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")"
      ],
      "metadata": {
        "id": "9fFqJ4NiQ5PG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_review_text(text: str) -> str:\n",
        "\n",
        "    text = re.sub(r'[^\\w\\s.,@#()-/:]', '', text)\n",
        "    # Normalize whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "Mk8Ff39gQ9Z4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_review_details(review_text: str) -> ReviewExtractionOutput:\n",
        "    cleaned_text = clean_review_text(review_text)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an expert assistant that extracts key details from customer reviews. Analyze the following review and extract:\n",
        "\n",
        "1. Customer's name\n",
        "2. Customer's ID\n",
        "3. Product name\n",
        "4. Company/store name\n",
        "5. Sentiment of the customer (positive, negative, neutral)\n",
        "6. Specific pros (what was good about the product)\n",
        "7. Specific cons (what was bad about the product)\n",
        "\n",
        "Do NOT add any explanations or extra text.\n",
        "\n",
        "Review:\n",
        "\\\"\\\"\\\"{cleaned_text}\\\"\\\"\\\"\n",
        "\n",
        "Strictly respond following the below schema:\n",
        "{parser.get_format_instructions()}\n",
        "\"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "    cleaned_output = response.content.strip()\n",
        "    parsed_output = parser.parse(cleaned_output)\n",
        "    return parsed_output"
      ],
      "metadata": {
        "id": "1bFzxifeRAwy"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_text = \"\"\"@Customer: Varun D. Kapoor (ID#: CRM5543219) | Purchase Date: 22/10/2023 | Store: Croma Electronics, DLF Mall Branch, Sector 18, Noida, UP - 201301 | Product: Pebble BassX Prime™ Wireless Speaker (#PBL-SPK22) | Order #: CRM/DLF/2023/10/7788 ✨ What a FANTASTIC buy @ just ₹2,499/-! Been using this Pebble speaker for 3 weeks & honestly amazed by the value for money 🎵. Sales rep @Amit (ID#CR567) recommended this over expensive brands & boy was he right! Let me tell you why this budget speaker is punching way above its weight -> First off, the BASS!!! For this price point, totally unexpected depth & clarity = perfect party companion 🔊. Battery life is IMPRESSIVE: advertised 8hrs but I'm getting solid 9.5hrs on 60% volume!!! RGB lights sync w/ music = creates nice ambiance (can be turned off too). Bluetooth 5.0 connection = zero lag & connects instantly w/ my iPhone & laptop. Range is solid, works through walls up to ~30ft ⚡. Delivery/setup experience was smooth: ordered @ 11am, delivered same day @ 4pm exactly as promised. Really appreciate the thoughtful additions: aux cable included + Type-C charging (finally!) + voice assistant compatible + IPX6 water resistance (survived a small rain splash already!) 💫. Sound quality for calls is crystal clear - using it for WFH meetings daily. The dual pairing feature lets me connect 2 phones simultaneously = super convenient for family use 📱. Build quality feels sturdy despite plastic body - survived 2 accidental drops w/o a scratch! Called customer support (#1800-123-4567) to understand equalizer settings → got helpful guidance in 1st attempt. Store manager @Deepak Sinha even shared his personal WhatsApp for any issues = great customer service! Only tiny suggestion: wish the manual was bit more detailed re: EQ settings. Getting so many compliments during house parties - friends can't believe the price when they hear the sound quality! Definitely exceeded expectations for a budget speaker - perfect balance of features & affordability 🌟. Already ordered another one for my parents! Big thumbs up to Pebble & Croma for this value-packed product. #PebbleSpeaker #BudgetBuy #QualitySound #PerfectChoice #HappyPurchase [Posted: 13/11/2023 | Review ID: REV34567890]\"\"\"\n",
        "\n",
        "result = extract_review_details(review_text)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0L9Bq-CRFZ4",
        "outputId": "b82d5494-cc21-41b6-cfae-fc461439e29b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "customer_name='Varun D. Kapoor' customer_id='CRM5543219' product='Pebble BassX Prime Wireless Speaker (#PBL-SPK22)' company='Croma Electronics' sentiment='positive' pros='value for money, deep bass, impressive battery life, RGB lights, Bluetooth 5.0 connection, solid range, smooth delivery and setup experience, thoughtful additions, crystal clear sound quality for calls, dual pairing feature, sturdy build quality, helpful customer support' cons='manual could be more detailed regarding EQ settings'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_text = \"\"\"@Customer: Aisha R. Sheikh (ID#: CRM9934567) | Purchase Date: 15/09/2023 | Store: Croma Electronics, Oberoi Mall Branch, Western Express Highway, Goregaon (E), Mumbai - 400063 | Product: Dyson Supersonic™ Hair Dryer (#HD07) | Order #: CRM/OBR/2023/09/6543 ⭐ Overall satisfied w/ my Dyson purchase though the price point (₹44,900/-) definitely makes you think twice! After 2 months of regular use, here's my balanced take -> The good stuff first: heat control is EXCELLENT, never burns my hair like old dryer & the magnetic attachments are quite clever 👍. Sales consultant @Ritu (ID#CR234) was knowledgeable & didn't oversell, appreciated her honesty about product features. The technology is impressive = consistent temp control + ion technology does make hair notably smoother ✨. Noise level is definitely lower than traditional dryers (but not \"whisper-quiet\" as advertised). Drying time reduced by ~40% which helps on busy mornings! Build quality feels premium & the box packaging was luxurious 📦. Now the not-so-perfect parts: The cord could be longer, sometimes awkward to maneuver @ current length. Weight distribution takes getting used to - different from traditional dryers but not necessarily better/worse 🤔. Installation/demo was scheduled 3-5pm, person arrived @ 5:30pm (bit late but acceptable). Price of additional attachments = quite steep! Called customer service (#1800-123-4567) once for attachment query → decent response time, somewhat helpful. Minor annoyance: cold shot button needs to be held down continuously = slightly inconvenient. Store manager @Vikas Patel provided good support w/ warranty registration. Would I recommend it? Yes, but only if you're okay w/ premium pricing & really care about hair care! Not a must-have but definitely a nice-to-have luxury item. Battery life & performance consistent so far = no complaints. Comes with 2yr warranty which is reassuring for expensive purchase. Fair product, works as advertised, but prepare for the investment! #DysonHair #PremiumProduct #DecentChoice #GoodEnough #ExpensiveButOk [Posted: 13/11/2023 | Review ID: REV45678901]\"\"\"\n",
        "\n",
        "result = extract_review_details(review_text)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1UfPElWRUL9",
        "outputId": "9330f0fa-4455-48a3-a50b-63432537f1c8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "customer_name='Aisha R. Sheikh' customer_id='CRM9934567' product='Dyson Supersonic Hair Dryer (#HD07)' company='Croma Electronics' sentiment='positive' pros='heat control, magnetic attachments, knowledgeable sales consultant, impressive technology, consistent temp control, ion technology, smoother hair, lower noise level, premium build quality, luxurious packaging, reduced drying time' cons='high price point, cord could be longer, weight distribution takes getting used to, installation/demo person arrived late, price of additional attachments is steep, cold shot button needs to be held down continuously'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_text = \"\"\"@Customer: Priya S. Mehta (ID#: CRM8765432) | Purchase Date: 05/10/2023 | Store: Croma Electronics, Phoenix MarketCity Branch, 1st Floor, LBS Marg, Kurla (W), Mumbai - 400070 | Product: Philips ProBlend™ Series 700W Juicer Mixer Grinder (#HL7763/80) | Order #: CRM/PHX/2023/10/8876 ✨ ABSOLUTELY IN LOVE w/ my new Philips JMG!!! Best ₹12,999/- ever spent @ Croma! Been using this powerhouse daily for >1 month now & can't stop raving about it 🌟. The 700W motor is a BEAST - transforms hard vegetables into silky smooth juice in seconds!!! Special shoutout to sales executive @Neha (ID#CR456) who gave excellent demo & helped choose perfect model for my family of 4. The 5 different speed settings + pulse function ➡️ game changer for different recipes! Made everything from smooth apple juice to tough coconut chutney = PERFECT results every time 😊. Love the special features: Auto-cut off protection (safety first!) + Anti-drip spout (no more counter mess!) + Extra-wide 75mm feeding tube (fits whole apples!!!). Super quiet compared to my old mixer - can blend early morning w/o waking kids 🎯. Installation & demo was scheduled 2-4pm, team arrived @ exactly 2:15pm! Very professional setup + explained all features thoroughly. The complimentary recipe book = BONUS! Already tried 8 recipes & each turned out amazing ⭐. Build quality is exceptional - all 3 jars feel premium & super sturdy. Sharp stainless-steel blades + 2yr warranty = total peace of mind! Power consumption very reasonable - negligible difference in electricity bill. Best part -> cleaning is SUPER EASY! All parts are dishwasher safe & come apart easily. No hidden corners where pulp gets stuck 💫. Customer service experience was outstanding - had a small query about attachments, called helpline (#1800-123-4567) → resolved in 5 mins! Store manager @Rohit Singh even called after 1 week to check if everything working fine = GREAT after-sales support! Getting so many compliments on my fresh juices & smoothies. Already recommended to 5 friends - 2 have bought same model! 100% value for money & worth every rupee. Thank you Croma & Philips for this amazing product!!! #HappyCustomer #PhilipsJMG #WorthEveryPenny #HealthyLiving #PerfectChoice [Posted: 13/11/2023 | Review ID: REV23456789]\"\"\"\n",
        "\n",
        "result = extract_review_details(review_text)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTf73lI5Risj",
        "outputId": "8d1f0d29-58e7-458d-fe5a-9d747b4b9d97"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "customer_name='Priya S. Mehta' customer_id='CRM8765432' product='Philips ProBlend Series 700W Juicer Mixer Grinder (#HL7763/80)' company='Croma Electronics' sentiment='positive' pros='700W motor, 5 different speed settings, pulse function, Auto-cut off protection, Anti-drip spout, Extra-wide 75mm feeding tube, super quiet, easy to clean, build quality, sharp stainless-steel blades, 2yr warranty' cons='None'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Structured format:"
      ],
      "metadata": {
        "id": "gr_FmX0TTfR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "from tabulate import tabulate"
      ],
      "metadata": {
        "id": "NIQa0bYAS2ZL"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = [\n",
        "    # Review 1\n",
        "    \"\"\"@Customer: Varun D. Kapoor (ID#: CRM5543219) | Purchase Date: 22/10/2023 | Store: Croma Electronics, DLF Mall Branch, Sector 18, Noida, UP - 201301 | Product: Pebble BassX Prime™ Wireless Speaker (#PBL-SPK22) | Order #: CRM/DLF/2023/10/7788 ✨ What a FANTASTIC buy @ just ₹2,499/-! Been using this Pebble speaker for 3 weeks & honestly amazed by the value for money 🎵. Sales rep @Amit (ID#CR567) recommended this over expensive brands & boy was he right! Let me tell you why this budget speaker is punching way above its weight -> First off, the BASS!!! For this price point, totally unexpected depth & clarity = perfect party companion 🔊. Battery life is IMPRESSIVE: advertised 8hrs but I'm getting solid 9.5hrs on 60% volume!!! RGB lights sync w/ music = creates nice ambiance (can be turned off too). Bluetooth 5.0 connection = zero lag & connects instantly w/ my iPhone & laptop. Range is solid, works through walls up to ~30ft ⚡. Delivery/setup experience was smooth: ordered @ 11am, delivered same day @ 4pm exactly as promised. Really appreciate the thoughtful additions: aux cable included + Type-C charging (finally!) + voice assistant compatible + IPX6 water resistance (survived a small rain splash already!) 💫. Sound quality for calls is crystal clear - using it for WFH meetings daily. The dual pairing feature lets me connect 2 phones simultaneously = super convenient for family use 📱. Build quality feels sturdy despite plastic body - survived 2 accidental drops w/o a scratch! Called customer support (#1800-123-4567) to understand equalizer settings → got helpful guidance in 1st attempt. Store manager @Deepak Sinha even shared his personal WhatsApp for any issues = great customer service! Only tiny suggestion: wish the manual was bit more detailed re: EQ settings. Getting so many compliments during house parties - friends can't believe the price when they hear the sound quality! Definitely exceeded expectations for a budget speaker - perfect balance of features & affordability 🌟. Already ordered another one for my parents! Big thumbs up to Pebble & Croma for this value-packed product. #PebbleSpeaker #BudgetBuy #QualitySound #PerfectChoice #HappyPurchase [Posted: 13/11/2023 | Review ID: REV34567890]\"\"\",  # truncated for brevity\n",
        "    # Review 2\n",
        "    \"\"\"@Customer: Aisha R. Sheikh (ID#: CRM9934567) | Purchase Date: 15/09/2023 | Store: Croma Electronics, Oberoi Mall Branch, Western Express Highway, Goregaon (E), Mumbai - 400063 | Product: Dyson Supersonic™ Hair Dryer (#HD07) | Order #: CRM/OBR/2023/09/6543 ⭐ Overall satisfied w/ my Dyson purchase though the price point (₹44,900/-) definitely makes you think twice! After 2 months of regular use, here's my balanced take -> The good stuff first: heat control is EXCELLENT, never burns my hair like old dryer & the magnetic attachments are quite clever 👍. Sales consultant @Ritu (ID#CR234) was knowledgeable & didn't oversell, appreciated her honesty about product features. The technology is impressive = consistent temp control + ion technology does make hair notably smoother ✨. Noise level is definitely lower than traditional dryers (but not \"whisper-quiet\" as advertised). Drying time reduced by ~40% which helps on busy mornings! Build quality feels premium & the box packaging was luxurious 📦. Now the not-so-perfect parts: The cord could be longer, sometimes awkward to maneuver @ current length. Weight distribution takes getting used to - different from traditional dryers but not necessarily better/worse 🤔. Installation/demo was scheduled 3-5pm, person arrived @ 5:30pm (bit late but acceptable). Price of additional attachments = quite steep! Called customer service (#1800-123-4567) once for attachment query → decent response time, somewhat helpful. Minor annoyance: cold shot button needs to be held down continuously = slightly inconvenient. Store manager @Vikas Patel provided good support w/ warranty registration. Would I recommend it? Yes, but only if you're okay w/ premium pricing & really care about hair care! Not a must-have but definitely a nice-to-have luxury item. Battery life & performance consistent so far = no complaints. Comes with 2yr warranty which is reassuring for expensive purchase. Fair product, works as advertised, but prepare for the investment! #DysonHair #PremiumProduct #DecentChoice #GoodEnough #ExpensiveButOk [Posted: 13/11/2023 | Review ID: REV45678901]\"\"\",\n",
        "    # Review 3\n",
        "    \"\"\"@Customer: Priya S. Mehta (ID#: CRM8765432) | Purchase Date: 05/10/2023 | Store: Croma Electronics, Phoenix MarketCity Branch, 1st Floor, LBS Marg, Kurla (W), Mumbai - 400070 | Product: Philips ProBlend™ Series 700W Juicer Mixer Grinder (#HL7763/80) | Order #: CRM/PHX/2023/10/8876 ✨ ABSOLUTELY IN LOVE w/ my new Philips JMG!!! Best ₹12,999/- ever spent @ Croma! Been using this powerhouse daily for >1 month now & can't stop raving about it 🌟. The 700W motor is a BEAST - transforms hard vegetables into silky smooth juice in seconds!!! Special shoutout to sales executive @Neha (ID#CR456) who gave excellent demo & helped choose perfect model for my family of 4. The 5 different speed settings + pulse function ➡️ game changer for different recipes! Made everything from smooth apple juice to tough coconut chutney = PERFECT results every time 😊. Love the special features: Auto-cut off protection (safety first!) + Anti-drip spout (no more counter mess!) + Extra-wide 75mm feeding tube (fits whole apples!!!). Super quiet compared to my old mixer - can blend early morning w/o waking kids 🎯. Installation & demo was scheduled 2-4pm, team arrived @ exactly 2:15pm! Very professional setup + explained all features thoroughly. The complimentary recipe book = BONUS! Already tried 8 recipes & each turned out amazing ⭐. Build quality is exceptional - all 3 jars feel premium & super sturdy. Sharp stainless-steel blades + 2yr warranty = total peace of mind! Power consumption very reasonable - negligible difference in electricity bill. Best part -> cleaning is SUPER EASY! All parts are dishwasher safe & come apart easily. No hidden corners where pulp gets stuck 💫. Customer service experience was outstanding - had a small query about attachments, called helpline (#1800-123-4567) → resolved in 5 mins! Store manager @Rohit Singh even called after 1 week to check if everything working fine = GREAT after-sales support! Getting so many compliments on my fresh juices & smoothies. Already recommended to 5 friends - 2 have bought same model! 100% value for money & worth every rupee. Thank you Croma & Philips for this amazing product!!! #HappyCustomer #PhilipsJMG #WorthEveryPenny #HealthyLiving #PerfectChoice [Posted: 13/11/2023 | Review ID: REV23456789]\"\"\",\n",
        "\n",
        "]\n",
        "\n",
        "# Step 6: Process all in parallel\n",
        "def process_all_reviews(review_list):\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        results = list(executor.map(extract_review_details, review_list))\n",
        "    return results\n",
        "\n",
        "# Step 7: Format and display result\n",
        "def display_results(results):\n",
        "    table = []\n",
        "    for r in results:\n",
        "        table.append([\n",
        "            r.customer_name,\n",
        "            r.customer_id,\n",
        "            r.product,\n",
        "            r.company,\n",
        "            r.sentiment,\n",
        "            r.pros[:50] + ('...' if len(r.pros) > 50 else ''),\n",
        "            r.cons[:50] + ('...' if len(r.cons) > 50 else '')\n",
        "        ])\n",
        "    headers = [\"Customer\", \"ID\", \"Product\", \"Company\", \"Sentiment\", \"Pros\", \"Cons\"]\n",
        "    print(tabulate(table, headers=headers, tablefmt=\"grid\"))"
      ],
      "metadata": {
        "id": "JpjzOxloScar"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = process_all_reviews(reviews)\n",
        "display_results(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbVBLc82SyV0",
        "outputId": "f8822f93-5aca-45e0-9555-ff16a1318125"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+------------+----------------------------------------------------------------+-------------------+-------------+-------------------------------------------------------+-------------------------------------------------------+\n",
            "| Customer        | ID         | Product                                                        | Company           | Sentiment   | Pros                                                  | Cons                                                  |\n",
            "+=================+============+================================================================+===================+=============+=======================================================+=======================================================+\n",
            "| Varun D. Kapoor | CRM5543219 | Pebble BassX Prime Wireless Speaker (#PBL-SPK22)               | Croma Electronics | positive    | value for money, deep bass, impressive battery lif... | manual could be more detailed regarding EQ setting... |\n",
            "+-----------------+------------+----------------------------------------------------------------+-------------------+-------------+-------------------------------------------------------+-------------------------------------------------------+\n",
            "| Aisha R. Sheikh | CRM9934567 | Dyson Supersonic Hair Dryer                                    | Croma Electronics | positive    | heat control, magnetic attachments, knowledgeable ... | high price point, cord could be longer, weight dis... |\n",
            "+-----------------+------------+----------------------------------------------------------------+-------------------+-------------+-------------------------------------------------------+-------------------------------------------------------+\n",
            "| Priya S. Mehta  | CRM8765432 | Philips ProBlend Series 700W Juicer Mixer Grinder (#HL7763/80) | Croma Electronics | positive    | 700W motor, 5 different speed settings, pulse func... | None                                                  |\n",
            "+-----------------+------------+----------------------------------------------------------------+-------------------+-------------+-------------------------------------------------------+-------------------------------------------------------+\n"
          ]
        }
      ]
    }
  ]
}